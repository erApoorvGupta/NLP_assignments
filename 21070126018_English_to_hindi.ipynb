{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "ct5JhT-CLpuF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW4ow_yyKdlg",
        "outputId": "8f09c747-5d61-4d3b-d185-8359eb488967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,RepeatVector,TimeDistributed,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from string import digits\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "EyvXyPyXLjnH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NLP_LAB/Hindi_English_Truncated_Corpus.csv')\n",
        "data['source'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zGngdxLMtAU",
        "outputId": "f5867c56-2073-4f44-cdaa-242b61bc8fa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: source, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[(data.english_sentence.apply(lambda x: len(str(x))<=30))&\n",
        "          (data.hindi_sentence.apply(lambda x: len(str(x))<=30))]\n"
      ],
      "metadata": {
        "id": "gUKxHLtDNV25"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## changing uppercase to lowercase\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: str(x).lower())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())\n",
        "\n",
        "#Remove quotes\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x:re.sub(\"'\",'',x))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:re.sub(\"'\",'',x))\n",
        "\n",
        "to_exclude=set(string.punctuation) #set of all special character\n",
        "print(\"punctuations to exclude::\",to_exclude)\n",
        "\n",
        "#remove all the special characters\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in to_exclude))\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in to_exclude))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLmMeISLN5sP",
        "outputId": "61525e8a-50bd-4bfb-a3b0-36fe41062522"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punctuations to exclude:: {'[', '+', '`', '\\\\', '~', '{', ']', '$', '^', '*', '_', '<', ';', '.', '/', ':', '@', '\"', ',', '?', \"'\", '#', '(', '&', '!', ')', '}', '%', '>', '-', '=', '|'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import digits\n",
        "#Remove all numbers from text\n",
        "remove_digits=str.maketrans('','',digits)\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:x.translate(remove_digits))\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\",\"\",x))\n",
        "\n",
        "#Remove extra spaces\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: x.strip())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.strip())\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\" +\",\" \",x))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\" +\",\" \",x))"
      ],
      "metadata": {
        "id": "HsHW-U3ORUkh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4xu2334IUHgv",
        "outputId": "40c04029-f87a-4095-faa6-3606dd49a561"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       source             english_sentence                hindi_sentence\n",
              "11  indic2012      category religious text              श्रेणीधर्मग्रन्थ\n",
              "23        ted          this changed slowly          धीरे धीरे ये सब बदला\n",
              "26        ted          were being produced       उत्पन्न नहीं कि जाती थी\n",
              "33  indic2012                        maine                           मेन\n",
              "35        ted  can you imagine saying that  क्या आप ये कल्पना कर सकते है"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0df3d7bf-e196-45df-982a-5fab08ffc21b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>category religious text</td>\n",
              "      <td>श्रेणीधर्मग्रन्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ted</td>\n",
              "      <td>this changed slowly</td>\n",
              "      <td>धीरे धीरे ये सब बदला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ted</td>\n",
              "      <td>were being produced</td>\n",
              "      <td>उत्पन्न नहीं कि जाती थी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>maine</td>\n",
              "      <td>मेन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ted</td>\n",
              "      <td>can you imagine saying that</td>\n",
              "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0df3d7bf-e196-45df-982a-5fab08ffc21b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0df3d7bf-e196-45df-982a-5fab08ffc21b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0df3d7bf-e196-45df-982a-5fab08ffc21b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-818aa3b4-e34f-472a-9648-45799e9e5cae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-818aa3b4-e34f-472a-9648-45799e9e5cae')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-818aa3b4-e34f-472a-9648-45799e9e5cae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=[]\n",
        "target_text=[]\n",
        "input_characters=set()\n",
        "target_characters=set()\n",
        "\n",
        "for eng, hin in data[['english_sentence','hindi_sentence']].itertuples(index=False):\n",
        "  target='START_'+ hin +'_END' #end sequence\n",
        "  input_text.append(eng)\n",
        "  target_text.append(target)\n",
        "\n",
        "  for eng_char in eng.split():\n",
        "    if eng_char not in input_characters:\n",
        "      input_characters.add(eng_char)\n",
        "\n",
        "  for hin_char in hin.split():\n",
        "    if hin_char not in target_characters:\n",
        "      target_characters.add(hin_char)"
      ],
      "metadata": {
        "id": "Ktzd1i0xUUN-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(input_text))\n",
        "print(len(target_text))\n",
        "print(len(input_characters))\n",
        "print(len(target_characters))"
      ],
      "metadata": {
        "id": "DpFv8uyuXBjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99790a22-103f-4488-9ef9-d081b1c69ada"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18416\n",
            "18416\n",
            "9729\n",
            "8665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input Text ->>>>>\"+input_text[0] + \"->>>>>>> Output Text ->>>>>>>\"+target_text[0])"
      ],
      "metadata": {
        "id": "SZZb64a-XOqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d3b963-e8ce-42b0-b3b0-e9bbafb0c80f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text ->>>>>category religious text->>>>>>> Output Text ->>>>>>>START_श्रेणीधर्मग्रन्थ_END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_char=sorted(list(input_characters))\n",
        "target_char=sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens=len(input_characters)\n",
        "num_decoder_tokens=len(target_characters)+1\n",
        "\n",
        "max_encoder_seq_length=max([len(txt) for txt in input_text])\n",
        "max_decoder_seq_length=max([len(txt) for txt in target_text])"
      ],
      "metadata": {
        "id": "6xGkLlH0ZuCj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of samples:',len(input_text))\n",
        "print('Number of unique input tokens:',num_encoder_tokens)\n",
        "print('Number of unique tokens output tokens:',num_encoder_tokens)\n",
        "print('Max sequence length for inputs:',max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:',max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oiFWajjaszi",
        "outputId": "9b2bdd2b-4aab-4800-be4b-c92bb1db1c08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 18416\n",
            "Number of unique input tokens: 9729\n",
            "Number of unique tokens output tokens: 9729\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_char)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_char)])"
      ],
      "metadata": {
        "id": "7XW60NtWbfFm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "metadata": {
        "id": "wqv0yzuIhxsM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(input_token_index, open('eng_input_token_index.pickle','wb'),protocol=pickle.HIGHEST_PROTOCOL)\n",
        "pickle.dump(target_token_index, open('hin_target_token_index.pickle','wb'),protocol=pickle.HIGHEST_PROTOCOL)\n",
        "pickle.dump(reverse_input_char_index, open('eng_reverse_input_char_index.pickle','wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
        "pickle.dump(reverse_target_char_index, open('hin_reverse_target_char_index.pickle','wb'), protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "i23aEDqch30B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('eng_input_token_index.pickle','rb') as fp:\n",
        "  input_token_index = pickle.load(fp)\n",
        "with open('hin_target_token_index.pickle','rb') as fp:\n",
        "  target_token_index = pickle.load(fp)\n",
        "with open('eng_reverse_input_char_index.pickle','rb') as fp:\n",
        "  reverse_input_char_index = pickle.load(fp)\n",
        "with open('hin_reverse_target_char_index.pickle','rb') as fp:\n",
        "  reverse_target_char_index = pickle.load(fp)"
      ],
      "metadata": {
        "id": "T1QYmwuliN8t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, y = data.english_sentence, data.hindi_sentence\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1,random_state=2)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvwGbkh3iYju",
        "outputId": "f9159be3-06a5-4f37-fa3a-9cca0797e6bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16574,), (1842,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(X,y,batch_size):\n",
        "  while True:\n",
        "    for j in range(0, len(X),batch_size):\n",
        "      encoder_input_data = np.zeros((batch_size,max_encoder_seq_length),dtype='float32')\n",
        "      decoder_input_data = np.zeros((batch_size,max_decoder_seq_length),dtype='float32')\n",
        "      decoder_target_data = np.zeros((batch_size, max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "      for i,(input_text, target_text) in enumerate(zip(X[j:j+batch_size],y[j:j+batch_size])):\n",
        "        for t, word in enumerate(input_text.split()):\n",
        "          encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "          for t, word in enumerate(target_text.split()):\n",
        "            if t<len(target_text.split())-1:\n",
        "              decoder_input_data[i, t] = target_token_index[word] # decoder input␣seq\n",
        "            if t>0:\n",
        "              decoder_target_data[i, t - 1, target_token_index[word]] = 1\n",
        "              yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "metadata": {
        "id": "IH8AOZIkieTB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 50"
      ],
      "metadata": {
        "id": "jlRuPWzljewq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero =True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "REbpBsrLj6Db"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "bv05ecXvj8VH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "id": "VACfBcwIkCN0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R9WDssAkFb7",
        "outputId": "6c890bb4-80db-43d7-9f0f-842b62e1a316"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 50)             486450    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 50)             433300    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 50),                 20200     ['embedding[0][0]']           \n",
            "                              (None, 50),                                                         \n",
            "                              (None, 50)]                                                         \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 50),           20200     ['embedding_1[0][0]',         \n",
            "                              (None, 50),                            'lstm[0][1]',                \n",
            "                              (None, 50)]                            'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 8666)           441966    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1402116 (5.35 MB)\n",
            "Trainable params: 1402116 (5.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 512\n",
        "epochs = 45"
      ],
      "metadata": {
        "id": "VZh-xLxHkI4A"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    generator=generate_batch(X_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n",
        "    validation_steps=val_samples // batch_size\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUb4IMhukQ-d",
        "outputId": "480437fc-0bce-4dda-cc8e-d6fe1b4586db"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-c06b0b25cab3>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "32/32 [==============================] - 60s 1s/step - loss: 8.8221 - acc: 0.3498 - val_loss: 6.5481 - val_acc: 0.0000e+00\n",
            "Epoch 2/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 7.7786 - acc: 0.1832 - val_loss: 9.0925 - val_acc: 0.0000e+00\n",
            "Epoch 3/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 4.8414 - acc: 0.0671 - val_loss: 8.5060 - val_acc: 0.0000e+00\n",
            "Epoch 4/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 4.7249 - acc: 0.0901 - val_loss: 10.6664 - val_acc: 0.0000e+00\n",
            "Epoch 5/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 4.7313 - acc: 0.0802 - val_loss: 10.4426 - val_acc: 0.0000e+00\n",
            "Epoch 6/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 4.3228 - acc: 0.0729 - val_loss: 10.3772 - val_acc: 0.0000e+00\n",
            "Epoch 7/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 4.3608 - acc: 0.0800 - val_loss: 10.6159 - val_acc: 0.1111\n",
            "Epoch 8/45\n",
            "32/32 [==============================] - 42s 1s/step - loss: 4.2842 - acc: 0.0865 - val_loss: 10.8135 - val_acc: 0.1111\n",
            "Epoch 9/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 4.3700 - acc: 0.0983 - val_loss: 10.8797 - val_acc: 0.1111\n",
            "Epoch 10/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 4.2796 - acc: 0.0947 - val_loss: 9.6401 - val_acc: 0.0833\n",
            "Epoch 11/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 4.2119 - acc: 0.0837 - val_loss: 9.8750 - val_acc: 0.1429\n",
            "Epoch 12/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 4.0408 - acc: 0.0969 - val_loss: 9.6689 - val_acc: 0.1277\n",
            "Epoch 13/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 4.0175 - acc: 0.0897 - val_loss: 9.9451 - val_acc: 0.0588\n",
            "Epoch 14/45\n",
            "32/32 [==============================] - 37s 1s/step - loss: 3.9953 - acc: 0.1090 - val_loss: 9.7832 - val_acc: 0.0536\n",
            "Epoch 15/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 3.8381 - acc: 0.1341 - val_loss: 9.7122 - val_acc: 0.0441\n",
            "Epoch 16/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 3.6766 - acc: 0.1416 - val_loss: 10.5232 - val_acc: 0.0435\n",
            "Epoch 17/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 3.5252 - acc: 0.1546 - val_loss: 10.3000 - val_acc: 0.0435\n",
            "Epoch 18/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 3.3050 - acc: 0.2295 - val_loss: 10.2817 - val_acc: 0.0435\n",
            "Epoch 19/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 3.2064 - acc: 0.2980 - val_loss: 10.0876 - val_acc: 0.0870\n",
            "Epoch 20/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 3.0795 - acc: 0.3702 - val_loss: 10.0842 - val_acc: 0.0870\n",
            "Epoch 21/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 2.7755 - acc: 0.4695 - val_loss: 9.9064 - val_acc: 0.0741\n",
            "Epoch 22/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 2.6306 - acc: 0.5467 - val_loss: 10.1314 - val_acc: 0.0741\n",
            "Epoch 23/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 2.5332 - acc: 0.5807 - val_loss: 10.0346 - val_acc: 0.0370\n",
            "Epoch 24/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 2.2585 - acc: 0.6406 - val_loss: 9.7859 - val_acc: 0.0667\n",
            "Epoch 25/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 1.9497 - acc: 0.7553 - val_loss: 10.0898 - val_acc: 0.0667\n",
            "Epoch 26/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 1.7525 - acc: 0.7982 - val_loss: 10.0110 - val_acc: 0.0947\n",
            "Epoch 27/45\n",
            "32/32 [==============================] - 37s 1s/step - loss: 1.6054 - acc: 0.8151 - val_loss: 10.4166 - val_acc: 0.0857\n",
            "Epoch 28/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 1.5162 - acc: 0.8316 - val_loss: 10.4985 - val_acc: 0.0857\n",
            "Epoch 29/45\n",
            "32/32 [==============================] - 37s 1s/step - loss: 1.3193 - acc: 0.8563 - val_loss: 10.9270 - val_acc: 0.0857\n",
            "Epoch 30/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 1.1696 - acc: 0.8918 - val_loss: 11.1906 - val_acc: 0.0571\n",
            "Epoch 31/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 1.1254 - acc: 0.9067 - val_loss: 10.9966 - val_acc: 0.0561\n",
            "Epoch 32/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 1.0864 - acc: 0.9155 - val_loss: 10.6090 - val_acc: 0.0783\n",
            "Epoch 33/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 0.9255 - acc: 0.9311 - val_loss: 10.2736 - val_acc: 0.0756\n",
            "Epoch 34/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 0.9170 - acc: 0.9299 - val_loss: 9.8365 - val_acc: 0.0746\n",
            "Epoch 35/45\n",
            "32/32 [==============================] - 37s 1s/step - loss: 0.9112 - acc: 0.9210 - val_loss: 9.6783 - val_acc: 0.0889\n",
            "Epoch 36/45\n",
            "32/32 [==============================] - 41s 1s/step - loss: 0.8662 - acc: 0.9192 - val_loss: 9.8693 - val_acc: 0.0667\n",
            "Epoch 37/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 0.7992 - acc: 0.9377 - val_loss: 9.6326 - val_acc: 0.0667\n",
            "Epoch 38/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 0.7830 - acc: 0.9368 - val_loss: 9.6263 - val_acc: 0.0876\n",
            "Epoch 39/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 0.7534 - acc: 0.9400 - val_loss: 9.8826 - val_acc: 0.0816\n",
            "Epoch 40/45\n",
            "32/32 [==============================] - 38s 1s/step - loss: 0.6672 - acc: 0.9499 - val_loss: 9.8719 - val_acc: 0.0612\n",
            "Epoch 41/45\n",
            "32/32 [==============================] - 40s 1s/step - loss: 0.6442 - acc: 0.9540 - val_loss: 9.9339 - val_acc: 0.0408\n",
            "Epoch 42/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 0.6343 - acc: 0.9485 - val_loss: 9.7375 - val_acc: 0.0592\n",
            "Epoch 43/45\n",
            "32/32 [==============================] - 36s 1s/step - loss: 0.5355 - acc: 0.9589 - val_loss: 9.6847 - val_acc: 0.0755\n",
            "Epoch 44/45\n",
            "32/32 [==============================] - 39s 1s/step - loss: 0.4621 - acc: 0.9676 - val_loss: 9.7306 - val_acc: 0.1132\n",
            "Epoch 45/45\n",
            "32/32 [==============================] - 36s 1s/step - loss: 0.4549 - acc: 0.9721 - val_loss: 9.7260 - val_acc: 0.0755\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78b9e2ca6b90>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('nmt_eng_hin_translation.h5')"
      ],
      "metadata": {
        "id": "nBsC7ff4kTUZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "3YGjHfxjzXiC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "metadata": {
        "id": "L1bBuf1xz_Qj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder␣sequence\n",
        "# To predict the next word in the sequence, set the initial states to the␣states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2,initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "tFdRIcvU0DXz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    #target_seq[0, 0] = target_token_index['START_']  # Start with the START_ token\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while True:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "\n",
        "        if sampled_char == '_END' or len(decoded_sentence.split()) > max_decoder_seq_length:\n",
        "            break\n",
        "\n",
        "        decoded_sentence += ' ' + sampled_char\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "# Now you can use the decode_sequence function without running endlessly\n",
        "val_gen = generate_batch(X_test, y_test, batch_size=1)\n",
        "k = -1\n",
        "\n",
        "k += 2\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_test[k:k+1].values[0])\n",
        "print('Predicted Hindi Translation:', decoded_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rUe-1Fj0SZT",
        "outputId": "7fb2d73a-fe4a-42f3-b395-ffb6fbf837de"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Input English sentence: i have a little acorn here\n",
            "Actual Hindi Translation: मेरे पास एक छोटा सा बाँजफ़ल है\n",
            "Predicted Hindi Translation: चली है और है सब अच्छा हो आये थे थे थे थे लिए। लिए। लिए। के लिए। है लिए। है लिये। है लिये। है लिये। के लिये। है लिये। है लिये। है हूँ आये थे के लिए। के लिए। के लिये।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35YMnlyx1EKt"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}